{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmrzg5rb+ZDQPWPJWTBKS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "26dd980f9389411087b15c8a715d5337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9abd949995a42f5a6a5ba0cb83a9795",
              "IPY_MODEL_bf6b619ccad745508820040731be8194",
              "IPY_MODEL_f2de6906219047b6b15aef9001a8dada"
            ],
            "layout": "IPY_MODEL_d695121adcc94570b84dff7a2b66f9d7"
          }
        },
        "c9abd949995a42f5a6a5ba0cb83a9795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c30ed2f3ea74988a6f287840674c40c",
            "placeholder": "​",
            "style": "IPY_MODEL_65e30600a64e4179a8c992be2e8b10f7",
            "value": "embedding nodes: 100%"
          }
        },
        "bf6b619ccad745508820040731be8194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9014cd3a3fee47b089f446c934531936",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f06e5285b4f64ab3a62faa4f2b15a233",
            "value": 22
          }
        },
        "f2de6906219047b6b15aef9001a8dada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9697e96eefa84100b3e9a5614005a399",
            "placeholder": "​",
            "style": "IPY_MODEL_35c5691ad0314a33b4c2e624403d87a6",
            "value": " 22/22 [00:03&lt;00:00,  3.03it/s]"
          }
        },
        "d695121adcc94570b84dff7a2b66f9d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "8c30ed2f3ea74988a6f287840674c40c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e30600a64e4179a8c992be2e8b10f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9014cd3a3fee47b089f446c934531936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f06e5285b4f64ab3a62faa4f2b15a233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9697e96eefa84100b3e9a5614005a399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35c5691ad0314a33b4c2e624403d87a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87297acf95f44ff0a63f2ba2ae8a860e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d121a77232547909d82fcc35dcf0cd8",
              "IPY_MODEL_bbb807e1f81e40e6b279a23d6564b9c6",
              "IPY_MODEL_84456dc8e9f14596beb2004d6085037e"
            ],
            "layout": "IPY_MODEL_bee10526eab74bd683ed14ba90241c5c"
          }
        },
        "9d121a77232547909d82fcc35dcf0cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_355875b6ca874ecaa8642002f8fea7b8",
            "placeholder": "​",
            "style": "IPY_MODEL_0935502bfb6d49be807a63893b4d314b",
            "value": "Generating: 100%"
          }
        },
        "bbb807e1f81e40e6b279a23d6564b9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66c27fa603024f638e63607e6faa4fb4",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95d92e87c6aa47f6ba232e41c06035ca",
            "value": 5
          }
        },
        "84456dc8e9f14596beb2004d6085037e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daaac8aa920e47e492f175996143389a",
            "placeholder": "​",
            "style": "IPY_MODEL_550c3ed2a05e4ad8881d14163e755733",
            "value": " 5/5 [02:12&lt;00:00, 34.90s/it]"
          }
        },
        "bee10526eab74bd683ed14ba90241c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355875b6ca874ecaa8642002f8fea7b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0935502bfb6d49be807a63893b4d314b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66c27fa603024f638e63607e6faa4fb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d92e87c6aa47f6ba232e41c06035ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "daaac8aa920e47e492f175996143389a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "550c3ed2a05e4ad8881d14163e755733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2406724216e4217aae6e91a840d9772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01aa733e252b45f0ad04bd26fca0005c",
              "IPY_MODEL_71c156aa0ea64e89b9186941ef1070ef",
              "IPY_MODEL_96f44a11fec348f39c041e042745a8a6"
            ],
            "layout": "IPY_MODEL_c277b22215e841a69e515dfe007f2ff2"
          }
        },
        "01aa733e252b45f0ad04bd26fca0005c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2c954e5a06b4913a253b5befb2d68aa",
            "placeholder": "​",
            "style": "IPY_MODEL_f51b05f424244dd489fe3b811bb4b765",
            "value": "Evaluating: 100%"
          }
        },
        "71c156aa0ea64e89b9186941ef1070ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85bd43e28cda45219271e68efed5532e",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_041819ba52e34179898a27993011551d",
            "value": 20
          }
        },
        "96f44a11fec348f39c041e042745a8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bec4a40c205415d8e53756601d48509",
            "placeholder": "​",
            "style": "IPY_MODEL_1e61371727804827919e6f1a195ab3e7",
            "value": " 20/20 [01:26&lt;00:00,  7.38s/it]"
          }
        },
        "c277b22215e841a69e515dfe007f2ff2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c954e5a06b4913a253b5befb2d68aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f51b05f424244dd489fe3b811bb4b765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85bd43e28cda45219271e68efed5532e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "041819ba52e34179898a27993011551d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6bec4a40c205415d8e53756601d48509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e61371727804827919e6f1a195ab3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0a140df17bc4099afe22a26336ffe5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed8264949e3942fbb6d8c6e746041665",
              "IPY_MODEL_5e8fd3eab1854a569deecf6e641ba893",
              "IPY_MODEL_1801bdb6590a4a2fb20c5ffa157c3c47"
            ],
            "layout": "IPY_MODEL_35df4e69267c4f7faf866e88f2b8c114"
          }
        },
        "ed8264949e3942fbb6d8c6e746041665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a91b82443224dc9bb6b3f50a70e5dce",
            "placeholder": "​",
            "style": "IPY_MODEL_c62f45c3ac6e40c4af89c778b4f99090",
            "value": "Evaluating: 100%"
          }
        },
        "5e8fd3eab1854a569deecf6e641ba893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da68a0f86d3243b4bb2a7f78c028685e",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_681541b774b7416993755cf1cdbbbf33",
            "value": 20
          }
        },
        "1801bdb6590a4a2fb20c5ffa157c3c47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63cc8f922bbb4a21a54ab259b606a4c8",
            "placeholder": "​",
            "style": "IPY_MODEL_409b6cc9828e4969b4afb75c27bb12af",
            "value": " 20/20 [01:37&lt;00:00, 10.21s/it]"
          }
        },
        "35df4e69267c4f7faf866e88f2b8c114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a91b82443224dc9bb6b3f50a70e5dce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c62f45c3ac6e40c4af89c778b4f99090": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da68a0f86d3243b4bb2a7f78c028685e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681541b774b7416993755cf1cdbbbf33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63cc8f922bbb4a21a54ab259b606a4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409b6cc9828e4969b4afb75c27bb12af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/win4r/mytest/blob/main/Ragas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import os\n",
        "\n",
        "# 设置NLTK数据路径\n",
        "nltk.data.path.append(\"/content/nltk_data\")\n",
        "\n",
        "# 如果目录不存在，创建它\n",
        "if not os.path.exists(\"/content/nltk_data\"):\n",
        "    os.makedirs(\"/content/nltk_data\")\n",
        "\n",
        "print(\"Downloading 'punkt'...\")\n",
        "nltk.download('punkt', download_dir=\"/content/nltk_data\", quiet=False)\n",
        "print(\"Download completed.\")\n",
        "\n",
        "# 验证下载\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "    print(\"'punkt' resource found successfully.\")\n",
        "except LookupError:\n",
        "    print(\"'punkt' resource not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sERCwf5AgTWQ",
        "outputId": "a62d0d0d-1343-4705-d9c8-b22a62f9840f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'punkt'...\n",
            "Download completed.\n",
            "'punkt' resource found successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fRoMhnxbvN2",
        "outputId": "5efc7a2b-3153-400a-c488-dba79bd561ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ragas\n",
            "  Downloading ragas-0.1.20-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ragas) (1.26.4)\n",
            "Collecting datasets (from ragas)\n",
            "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting tiktoken (from ragas)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain (from ragas)\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.3 (from ragas)\n",
            "  Downloading langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-community (from ragas)\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langchain-openai (from ragas)\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting openai>1 (from ragas)\n",
            "  Downloading openai-1.47.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting pysbd>=0.3.4 (from ragas)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from ragas) (1.6.0)\n",
            "Collecting appdirs (from ragas)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3->ragas) (6.0.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3->ragas)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.112 (from langchain-core<0.3->ragas)\n",
            "  Downloading langsmith-0.1.125-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3->ragas) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3->ragas) (2.9.2)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.3->ragas)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3->ragas) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>1->ragas) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>1->ragas)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>1->ragas)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>1->ragas) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.16.1)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->ragas)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (2.32.3)\n",
            "Collecting xxhash (from datasets->ragas)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets->ragas)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->ragas) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets->ragas) (0.24.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (2.0.35)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->ragas) (4.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain (from ragas)\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain->ragas)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community->ragas)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community (from ragas)\n",
            "  Downloading langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-openai (from ragas)\n",
            "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->ragas) (2024.9.11)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->ragas) (1.11.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (1.2.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>1->ragas)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3->ragas)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3->ragas)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m966.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3->ragas) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3->ragas) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->ragas) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets->ragas) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->ragas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading ragas-0.1.20-py3-none-any.whl (190 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.0/397.0 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.47.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.17-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.125-py3-none-any.whl (290 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: appdirs, xxhash, tenacity, pysbd, pyarrow, orjson, mypy-extensions, marshmallow, jsonpointer, jiter, h11, dill, typing-inspect, tiktoken, multiprocess, jsonpatch, httpcore, httpx, dataclasses-json, openai, langsmith, langchain-core, datasets, langchain-text-splitters, langchain-openai, langchain, langchain-community, ragas\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed appdirs-1.4.4 dataclasses-json-0.6.7 datasets-3.0.0 dill-0.3.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.16 langchain-community-0.2.17 langchain-core-0.2.41 langchain-openai-0.1.25 langchain-text-splitters-0.2.4 langsmith-0.1.125 marshmallow-3.22.0 multiprocess-0.70.16 mypy-extensions-1.0.0 openai-1.47.0 orjson-3.10.7 pyarrow-17.0.0 pysbd-0.3.4 ragas-0.1.20 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ragas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ESUw290doG7",
        "outputId": "67604938-dd61-45ad-afc4-a884afd95425"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unstructured\n",
            "  Downloading unstructured-0.15.13-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
            "Collecting filetype (from unstructured)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.3)\n",
            "Collecting emoji (from unstructured)\n",
            "  Downloading emoji-2.13.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.7)\n",
            "Collecting python-iso639 (from unstructured)\n",
            "  Downloading python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured)\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.26.4)\n",
            "Collecting rapidfuzz (from unstructured)\n",
            "  Downloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured)\n",
            "  Downloading unstructured_client-0.25.9-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.9.5)\n",
            "Collecting python-oxmsg (from unstructured)\n",
            "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2024.9.11)\n",
            "Collecting olefile (from python-oxmsg->unstructured)\n",
            "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2024.8.30)\n",
            "Requirement already satisfied: cryptography>=3.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (43.0.1)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured)\n",
            "  Downloading deepdiff-8.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (0.27.2)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured)\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.6.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (24.1)\n",
            "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
            "  Downloading pypdf-5.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n",
            "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
            "Collecting orderly-set==5.2.2 (from deepdiff>=6.0->unstructured-client->unstructured)\n",
            "  Downloading orderly_set-5.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured) (0.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured) (1.2.2)\n",
            "Downloading unstructured-0.15.13-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading emoji-2.13.0-py3-none-any.whl (553 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.2/553.2 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
            "Downloading rapidfuzz-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.25.9-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
            "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading pypdf-5.0.0-py3-none-any.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.8/292.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=4e9ba25a77bce63cf6fbff9c0a7b1dd11ee7dbe9718c5eee3727a753f1d26754\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: filetype, rapidfuzz, python-magic, python-iso639, pypdf, orderly-set, olefile, langdetect, jsonpath-python, emoji, backoff, requests-toolbelt, python-oxmsg, deepdiff, unstructured-client, unstructured\n",
            "Successfully installed backoff-2.2.1 deepdiff-8.0.1 emoji-2.13.0 filetype-1.2.0 jsonpath-python-1.0.6 langdetect-1.0.9 olefile-0.47 orderly-set-5.2.2 pypdf-5.0.0 python-iso639-2024.4.27 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.9.7 requests-toolbelt-1.0.0 unstructured-0.15.13 unstructured-client-0.25.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "# generator with openai models\n",
        "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
        "critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(\n",
        "    generator_llm,\n",
        "    critic_llm,\n",
        "    embeddings\n",
        ")\n",
        "\n",
        "# generate testset\n",
        "testset = generator.generate_with_langchain_docs(documents, test_size=5, distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "26dd980f9389411087b15c8a715d5337",
            "c9abd949995a42f5a6a5ba0cb83a9795",
            "bf6b619ccad745508820040731be8194",
            "f2de6906219047b6b15aef9001a8dada",
            "d695121adcc94570b84dff7a2b66f9d7",
            "8c30ed2f3ea74988a6f287840674c40c",
            "65e30600a64e4179a8c992be2e8b10f7",
            "9014cd3a3fee47b089f446c934531936",
            "f06e5285b4f64ab3a62faa4f2b15a233",
            "9697e96eefa84100b3e9a5614005a399",
            "35c5691ad0314a33b4c2e624403d87a6",
            "87297acf95f44ff0a63f2ba2ae8a860e",
            "9d121a77232547909d82fcc35dcf0cd8",
            "bbb807e1f81e40e6b279a23d6564b9c6",
            "84456dc8e9f14596beb2004d6085037e",
            "bee10526eab74bd683ed14ba90241c5c",
            "355875b6ca874ecaa8642002f8fea7b8",
            "0935502bfb6d49be807a63893b4d314b",
            "66c27fa603024f638e63607e6faa4fb4",
            "95d92e87c6aa47f6ba232e41c06035ca",
            "daaac8aa920e47e492f175996143389a",
            "550c3ed2a05e4ad8881d14163e755733"
          ]
        },
        "id": "eSpgZNkNb1zI",
        "outputId": "4f172676-d011-4be9-ea0c-b41d591ac94d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "embedding nodes:   0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26dd980f9389411087b15c8a715d5337"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87297acf95f44ff0a63f2ba2ae8a860e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = testset.to_pandas()\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2511
        },
        "id": "td0rDs0ndK1v",
        "outputId": "13e3cf97-8800-4694-be4e-c424b93d1176"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            question  \\\n",
              "0  How can customer reviews be grouped into clust...   \n",
              "1  What is the purpose of seed-word prompting in ...   \n",
              "2  How to use Multiple Choice prompt technique wi...   \n",
              "3  Why combine seed-word prompting with other tec...   \n",
              "4  How to use role prompting to guide ChatGPT's o...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [This technique is useful for tasks such as da...   \n",
              "1  [ generally composed of 3 main elements:\\n\\nta...   \n",
              "2  [net.\\n\\nRole: Poet\\n\\nPrompt formula: \"Genera...   \n",
              "3  [ generally composed of 3 main elements:\\n\\nta...   \n",
              "4  [ generally composed of 3 main elements:\\n\\nta...   \n",
              "\n",
              "                                        ground_truth evolution_type  \\\n",
              "0  The model should be provided with a set of cus...         simple   \n",
              "1  The purpose of seed-word prompting in generati...         simple   \n",
              "2  This technique presents a model with a questio...      reasoning   \n",
              "3  Seed-word prompting is combined with other tec...  multi_context   \n",
              "4  The role prompting technique is used to guide ...      reasoning   \n",
              "\n",
              "                                            metadata  episode_done  \n",
              "0  [{'source': 'test/book.txt', 'filename': 'book...          True  \n",
              "1  [{'source': 'test/book.txt', 'filename': 'book...          True  \n",
              "2  [{'source': 'test/book.txt', 'filename': 'book...          True  \n",
              "3  [{'source': 'test/book.txt', 'filename': 'book...          True  \n",
              "4  [{'source': 'test/book.txt', 'filename': 'book...          True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fb41ea6-bb04-46e7-9937-49562bd2343e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can customer reviews be grouped into clust...</td>\n",
              "      <td>[This technique is useful for tasks such as da...</td>\n",
              "      <td>The model should be provided with a set of cus...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'test/book.txt', 'filename': 'book...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the purpose of seed-word prompting in ...</td>\n",
              "      <td>[ generally composed of 3 main elements:\\n\\nta...</td>\n",
              "      <td>The purpose of seed-word prompting in generati...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'test/book.txt', 'filename': 'book...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How to use Multiple Choice prompt technique wi...</td>\n",
              "      <td>[net.\\n\\nRole: Poet\\n\\nPrompt formula: \"Genera...</td>\n",
              "      <td>This technique presents a model with a questio...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'test/book.txt', 'filename': 'book...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why combine seed-word prompting with other tec...</td>\n",
              "      <td>[ generally composed of 3 main elements:\\n\\nta...</td>\n",
              "      <td>Seed-word prompting is combined with other tec...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'test/book.txt', 'filename': 'book...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to use role prompting to guide ChatGPT's o...</td>\n",
              "      <td>[ generally composed of 3 main elements:\\n\\nta...</td>\n",
              "      <td>The role prompting technique is used to guide ...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'test/book.txt', 'filename': 'book...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fb41ea6-bb04-46e7-9937-49562bd2343e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fb41ea6-bb04-46e7-9937-49562bd2343e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fb41ea6-bb04-46e7-9937-49562bd2343e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-283e1af0-f6aa-450a-80f4-3cec66e65232\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-283e1af0-f6aa-450a-80f4-3cec66e65232')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-283e1af0-f6aa-450a-80f4-3cec66e65232 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What is the purpose of seed-word prompting in generating text with ChatGPT?\",\n          \"How to use role prompting to guide ChatGPT's output with other prompt engineering techniques?\",\n          \"How to use Multiple Choice prompt technique with ChatGPT for limited text generation options?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ground_truth\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The purpose of seed-word prompting in generating text with ChatGPT is to ensure that the generated text focuses on specific keywords or concepts. By providing seed words, the model can be guided to generate text that highlights or incorporates those words.\",\n          \"The role prompting technique is used to guide the output of ChatGPT by providing a specific role for the model to take on. This technique is useful for generating text that is tailored to a specific context or audience. To use the role prompting technique, you need to provide a clear and specific role for the model to take on. For example, if you are generating customer service responses, you would provide a role such as \\\"customer service representative\\\". By combining the role prompting technique with instruction prompting and seed-word prompting, you can enhance the output of ChatGPT.\",\n          \"This technique presents a model with a question or task and a set of predefined options as potential answers. It is useful for generating text that is limited to a specific set of options and can be used for question-answering, text completion, and other tasks. The model can generate text that is limited to the predefined options. To use the multiple-choice prompt with ChatGPT, the model should be provided with a question or task as input, along with a set of predefined options as potential answers. The prompt should also include information about the desired output, such as the type of text.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evolution_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"simple\",\n          \"reasoning\",\n          \"multi_context\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"metadata\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"episode_done\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLWRpXru7LGY",
        "outputId": "8e0d08ea-dab7-4c3a-b0c8-73033f9521e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        ")\n",
        "from ragas import evaluate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from datasets import Dataset\n",
        "\n",
        "# 假设df是你之前生成的testset的DataFrame\n",
        "questions = df[\"question\"].tolist()\n",
        "contexts = df[\"contexts\"].tolist()\n",
        "ground_truths = df[\"ground_truth\"].tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 假设这是chatbot的回答列表\n",
        "chatbot_answers = [\n",
        "    \"Customer reviews can be grouped into clusters based on sentiment using various techniques in natural language processing (NLP) and machine learning. Here’s a general approach to achieve this: 1. **Data Collection**: Gather customer reviews from various sources such as websites, social media, or surveys. 2. **Preprocessing**: Clean the text data by removing noise such as punctuation, special characters, and stop words. You may also want to convert all text to lowercase and perform stemming or lemmatization. 3. **Sentiment Analysis**: Use sentiment analysis techniques to classify the sentiment of each review. This can be done using: - **Lexicon-based methods**: Use predefined dictionaries of words associated with positive, negative, or neutral sentiments. - **Machine learning models**: Train models (e.g., logistic regression, support vector machines) on labeled datasets to classify sentiment. - **Deep learning models**: Use neural networks, such as LSTM or transformers (like BERT), for more nuanced sentiment analysis. 4. **Feature Extraction**: Convert the reviews into numerical representations. Common methods include: - **Bag of Words (BoW)**: Represents text as a frequency count of words. - **TF-IDF (Term Frequency-Inverse Document Frequency)**: Weighs the frequency of words by how common they are across all documents. - **Word Embeddings**: Use embeddings like Word2Vec or GloVe to capture semantic meaning. 5. **Clustering**: Apply clustering algorithms to group the reviews based on their sentiment scores and features. Common clustering techniques include: - **K-Means Clustering**: Partitions the data into K clusters based on feature similarity. - **Hierarchical Clustering**: Builds a tree of clusters based on distance metrics. - **DBSCAN**: Groups together points that are closely packed together, marking as outliers points that lie alone in low-density regions. 6. **Visualization**: Use visualization techniques such as t-SNE or PCA to reduce dimensionality and visualize the clusters for better interpretation. 7. **Analysis**: Analyze the clusters to understand the common themes or sentiments within each group. This can help in identifying customer satisfaction, dissatisfaction, and areas for improvement. By following these steps, customer reviews can be effectively grouped into clusters based on sentiment, providing valuable insights into customer opinions and experiences.\",\n",
        "    \"Seed-word prompting in generating text with ChatGPT serves several important purposes: 1. **Guiding Context**: Seed words provide a starting point or context for the model, helping it understand the topic or theme that the user wants to explore. This can lead to more relevant and coherent responses. 2. **Focusing the Output**: By using specific seed words, users can direct the model to generate content that aligns with their interests or needs. This helps in narrowing down the scope of the generated text. 3. **Enhancing Creativity**: Seed words can inspire creative outputs by introducing specific concepts or ideas that the model can elaborate on. This can be particularly useful in creative writing, brainstorming, or generating unique content. 4. **Improving Relevance**: When seed words are used, the model is more likely to produce responses that are relevant to the user's query. This reduces the chances of generating off-topic or unrelated content. 5. **Facilitating Structured Responses**: Seed words can help in structuring the response, especially in cases where a specific format or style is desired (e.g., lists, narratives, or technical explanations). 6. **Encouraging Specificity**: By providing seed words, users can encourage the model to focus on particular aspects of a topic, leading to more detailed and informative responses. Overall, seed-word prompting enhances the interaction between the user and the model, making the generated text more aligned with the user's expectations and requirements.\",\n",
        "    \"Using the Multiple Choice prompt technique with ChatGPT can help you generate limited text options effectively. Here’s how to implement this technique: 1. **Define the Context**: Start by clearly defining the context or topic you want to explore. This helps set the stage for the multiple-choice options. 2. **Create Clear Options**: Formulate a set of distinct and clear options that you want the model to choose from. Each option should be concise and relevant to the context. Aim for 3-5 options to keep it manageable. 3. **Use a Structured Prompt**: Structure your prompt to explicitly ask the model to choose from the provided options. You can phrase it like this: - Based on the following context, please choose the best option: [Context]. Options: A) [Option 1], B) [Option 2], C) [Option 3], D) [Option 4]. 4. **Encourage Elaboration**: If you want the model to provide reasoning or elaboration on the chosen option, you can add a follow-up request. For example: - Please choose the best option and explain why you chose it. 5. **Iterate if Necessary**: If the initial response doesn’t meet your expectations, you can refine your options or context and try again. This iterative process can help you hone in on the desired output. ### Example Here’s a practical example of how to use the Multiple Choice prompt technique: **Prompt**: Based on the following context, please choose the best option: 'What is the most effective way to improve customer satisfaction in a retail store?' Options: A) Implementing a loyalty program, B) Reducing prices, C) Enhancing staff training, D) Increasing store hours.### Expected Output The model might respond with something like: I choose option C) Enhancing staff training because well-trained staff can provide better service, address customer concerns more effectively, and create a positive shopping experience, which ultimately leads to higher customer satisfaction.By using this technique, you can effectively limit the text generation options and guide the model towards producing focused and relevant responses.\",\n",
        "    \"Combining seed-word prompting with other techniques in ChatGPT text generation can enhance the quality, relevance, and creativity of the generated content. Here are several reasons why this combination is beneficial: 1. **Enhanced Contextualization**: Seed-word prompting provides a specific starting point, while other techniques (like multiple-choice prompts or structured queries) can further refine the context. This leads to more coherent and contextually appropriate responses. 2. **Increased Relevance**: By using seed words alongside techniques like specifying the desired format or style, users can guide the model to produce outputs that are more aligned with their needs. This reduces the likelihood of irrelevant or off-topic content. 3. **Improved Creativity**: Combining seed words with brainstorming techniques or open-ended prompts can stimulate more creative responses. The seed words can serve as inspiration, while the other techniques encourage the model to explore various angles or ideas. 4. **Focused Output**: Techniques such as multiple-choice prompts can help narrow down the options for the model, while seed words set the thematic direction. This combination allows users to obtain focused outputs without overwhelming the model with too many possibilities. 5. **Structured Responses**: Using seed words in conjunction with structured prompts (like lists or outlines) can help organize the generated content. This is particularly useful for tasks that require clarity and structure, such as reports or summaries. 6. **Iterative Refinement**: Combining techniques allows for iterative refinement of the output. For example, a user can start with seed words, generate a response, and then use follow-up prompts to clarify or expand on specific points, leading to a more polished final product. 7. **Diverse Perspectives**: By integrating seed-word prompting with techniques that encourage exploration of different viewpoints (like asking for pros and cons), users can obtain a more comprehensive understanding of a topic. 8. **User Engagement**: Combining techniques can make the interaction more engaging for users. It allows for a more dynamic conversation where users can guide the model in real-time, leading to a more satisfying experience. In summary, combining seed-word prompting with other techniques in ChatGPT text generation creates a more powerful and flexible approach, enabling users to harness the model's capabilities more effectively and achieve their desired outcomes.\",\n",
        "    \"Role prompting is a technique where you assign a specific role or persona to ChatGPT to guide its output in a desired direction. When combined with other prompt engineering techniques, role prompting can enhance the quality and relevance of the generated text. Here’s how to effectively use role prompting alongside other techniques: ### Steps to Use Role Prompting with Other Techniques 1. **Define the Role**: Clearly specify the role you want ChatGPT to assume. This could be a professional (e.g., a doctor, teacher, or consultant), a character (e.g., a historical figure or fictional character), or a specific perspective (e.g., a skeptic or an enthusiast). 2. **Combine with Seed Words**: Use seed words to provide context for the role. For example: - As a financial advisor, please explain the benefits of investing in stocks. Seed words: 'diversification', 'long-term growth', 'risk management'. 3. **Incorporate Multiple-Choice Prompts**: After establishing the role, you can present multiple-choice options to guide the response further. For example: - As a travel expert, choose the best destination for a family vacation from the following options: A) Disneyland, B) National Park, C) Beach Resort. Explain your choice. 4. **Use Structured Prompts**: Ask the model to respond in a specific format that aligns with the role. For instance: - As a nutritionist, provide a meal plan for a week. Format: Day 1: Breakfast, Lunch, Dinner. 5. **Encourage Elaboration**: After the initial response, prompt the model to elaborate on its answer. For example: - As a historian, summarize the causes of World War I and then discuss the long-term impacts. 6. **Iterative Refinement**: Use follow-up questions to refine the output. For example: - As a marketing strategist, what are three key strategies for social media marketing? Can you elaborate on the first one? 7. **Set Constraints**: Specify any constraints or limitations to guide the output more effectively. For example: - As a budget travel expert, suggest three affordable travel destinations for under $500. ### Example of Role Prompting Combined with Other Techniques **Prompt**: As a career coach, please provide advice for someone looking to transition into a tech career. Seed words: 'skills', 'networking', 'resume'. Additionally, list three key steps to take in this transition. ### Expected Output The model might respond with: As a career coach, transitioning into a tech career involves several important steps. Here are three key steps to consider: 1. **Identify Transferable Skills**: Assess your current skills and see how they can apply to tech roles. Skills like problem-solving, communication, and project management are valuable in tech. 2. **Build a Network**: Connect with professionals in the tech industry through networking events, online forums, and social media platforms like LinkedIn. Networking can open doors to job opportunities and mentorship. 3. **Update Your Resume**: Tailor your resume to highlight relevant skills and experiences. Consider taking online courses or certifications to bolster your qualifications in specific tech areas.By using role prompting in conjunction with other prompt engineering techniques, you can effectively guide ChatGPT's output to be more relevant, structured, and aligned with your specific needs. This approach enhances the interaction and helps achieve more satisfactory results.\"\n",
        "]\n",
        "\n",
        "# 创建数据字典\n",
        "ds_dict = {\n",
        "    \"question\": questions,\n",
        "    \"contexts\": contexts,\n",
        "    \"answer\": chatbot_answers,\n",
        "    \"ground_truth\": ground_truths\n",
        "}\n",
        "\n",
        "# 创建 Dataset 对象\n",
        "dataset = Dataset.from_dict(ds_dict)\n",
        "\n",
        "# 定义评估指标\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "]\n",
        "\n",
        "# 初始化评估用的LLM模型\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# 进行评估\n",
        "result = evaluate(\n",
        "    metrics=metrics,\n",
        "    dataset=dataset,\n",
        "    llm=evaluator_llm,\n",
        "    embeddings=OpenAIEmbeddings(),\n",
        ")\n",
        "\n",
        "# 打印评估结果\n",
        "print(result)\n",
        "\n",
        "# 将结果转换为pandas DataFrame以进行更详细的分析\n",
        "result_df = result.to_pandas()\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674,
          "referenced_widgets": [
            "e2406724216e4217aae6e91a840d9772",
            "01aa733e252b45f0ad04bd26fca0005c",
            "71c156aa0ea64e89b9186941ef1070ef",
            "96f44a11fec348f39c041e042745a8a6",
            "c277b22215e841a69e515dfe007f2ff2",
            "e2c954e5a06b4913a253b5befb2d68aa",
            "f51b05f424244dd489fe3b811bb4b765",
            "85bd43e28cda45219271e68efed5532e",
            "041819ba52e34179898a27993011551d",
            "6bec4a40c205415d8e53756601d48509",
            "1e61371727804827919e6f1a195ab3e7"
          ]
        },
        "id": "1yfkfu3M40Fg",
        "outputId": "e7bd4a3c-1e5e-4110-c0fa-a58b94abd813"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2406724216e4217aae6e91a840d9772"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'faithfulness': 0.1296, 'answer_relevancy': 0.9720, 'context_precision': 0.8000, 'context_recall': 0.9000}\n",
            "                                            question  \\\n",
            "0  How can customer reviews be grouped into clust...   \n",
            "1  What is the purpose of seed-word prompting in ...   \n",
            "2  How to use Multiple Choice prompt technique wi...   \n",
            "3  Why combine seed-word prompting with other tec...   \n",
            "4  How to use role prompting to guide ChatGPT's o...   \n",
            "\n",
            "                                            contexts  \\\n",
            "0  [This technique is useful for tasks such as da...   \n",
            "1  [ generally composed of 3 main elements:\\n\\nta...   \n",
            "2  [net.\\n\\nRole: Poet\\n\\nPrompt formula: \"Genera...   \n",
            "3  [ generally composed of 3 main elements:\\n\\nta...   \n",
            "4  [ generally composed of 3 main elements:\\n\\nta...   \n",
            "\n",
            "                                              answer  \\\n",
            "0  Customer reviews can be grouped into clusters ...   \n",
            "1  Seed-word prompting in generating text with Ch...   \n",
            "2  Using the Multiple Choice prompt technique wit...   \n",
            "3  Combining seed-word prompting with other techn...   \n",
            "4  Role prompting is a technique where you assign...   \n",
            "\n",
            "                                        ground_truth  faithfulness  \\\n",
            "0  The model should be provided with a set of cus...      0.111111   \n",
            "1  The purpose of seed-word prompting in generati...      0.000000   \n",
            "2  This technique presents a model with a questio...      0.125000   \n",
            "3  Seed-word prompting is combined with other tec...      0.176471   \n",
            "4  The role prompting technique is used to guide ...      0.235294   \n",
            "\n",
            "   answer_relevancy  context_precision  context_recall  \n",
            "0          1.000000                1.0             1.0  \n",
            "1          0.992385                0.0             0.5  \n",
            "2          0.974488                1.0             1.0  \n",
            "3          0.976731                1.0             1.0  \n",
            "4          0.916257                1.0             1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        ")\n",
        "from ragas import evaluate\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "# 假设df是你之前生成的testset的DataFrame\n",
        "questions = df[\"question\"].tolist()\n",
        "contexts = df[\"contexts\"].tolist()\n",
        "ground_truths = df[\"ground_truth\"].tolist()\n",
        "\n",
        "# 假设这是chatbot的回答列表\n",
        "chatbot_answers = [\n",
        "    \"Customer reviews can be grouped into clusters based on sentiment using various techniques in natural language processing (NLP) and machine learning. Here’s a general approach to achieve this: 1. **Data Collection**: Gather customer reviews from various sources such as websites, social media, or surveys. 2. **Preprocessing**: Clean the text data by removing noise such as punctuation, special characters, and stop words. You may also want to convert all text to lowercase and perform stemming or lemmatization. 3. **Sentiment Analysis**: Use sentiment analysis techniques to classify the sentiment of each review. This can be done using: - **Lexicon-based methods**: Use predefined dictionaries of words associated with positive, negative, or neutral sentiments. - **Machine learning models**: Train models (e.g., logistic regression, support vector machines) on labeled datasets to classify sentiment. - **Deep learning models**: Use neural networks, such as LSTM or transformers (like BERT), for more nuanced sentiment analysis. 4. **Feature Extraction**: Convert the reviews into numerical representations. Common methods include: - **Bag of Words (BoW)**: Represents text as a frequency count of words. - **TF-IDF (Term Frequency-Inverse Document Frequency)**: Weighs the frequency of words by how common they are across all documents. - **Word Embeddings**: Use embeddings like Word2Vec or GloVe to capture semantic meaning. 5. **Clustering**: Apply clustering algorithms to group the reviews based on their sentiment scores and features. Common clustering techniques include: - **K-Means Clustering**: Partitions the data into K clusters based on feature similarity. - **Hierarchical Clustering**: Builds a tree of clusters based on distance metrics. - **DBSCAN**: Groups together points that are closely packed together, marking as outliers points that lie alone in low-density regions. 6. **Visualization**: Use visualization techniques such as t-SNE or PCA to reduce dimensionality and visualize the clusters for better interpretation. 7. **Analysis**: Analyze the clusters to understand the common themes or sentiments within each group. This can help in identifying customer satisfaction, dissatisfaction, and areas for improvement. By following these steps, customer reviews can be effectively grouped into clusters based on sentiment, providing valuable insights into customer opinions and experiences.\",\n",
        "    \"Seed-word prompting in generating text with ChatGPT serves several important purposes: 1. **Guiding Context**: Seed words provide a starting point or context for the model, helping it understand the topic or theme that the user wants to explore. This can lead to more relevant and coherent responses. 2. **Focusing the Output**: By using specific seed words, users can direct the model to generate content that aligns with their interests or needs. This helps in narrowing down the scope of the generated text. 3. **Enhancing Creativity**: Seed words can inspire creative outputs by introducing specific concepts or ideas that the model can elaborate on. This can be particularly useful in creative writing, brainstorming, or generating unique content. 4. **Improving Relevance**: When seed words are used, the model is more likely to produce responses that are relevant to the user's query. This reduces the chances of generating off-topic or unrelated content. 5. **Facilitating Structured Responses**: Seed words can help in structuring the response, especially in cases where a specific format or style is desired (e.g., lists, narratives, or technical explanations). 6. **Encouraging Specificity**: By providing seed words, users can encourage the model to focus on particular aspects of a topic, leading to more detailed and informative responses. Overall, seed-word prompting enhances the interaction between the user and the model, making the generated text more aligned with the user's expectations and requirements.\",\n",
        "    \"Using the Multiple Choice prompt technique with ChatGPT can help you generate limited text options effectively. Here’s how to implement this technique: 1. **Define the Context**: Start by clearly defining the context or topic you want to explore. This helps set the stage for the multiple-choice options. 2. **Create Clear Options**: Formulate a set of distinct and clear options that you want the model to choose from. Each option should be concise and relevant to the context. Aim for 3-5 options to keep it manageable. 3. **Use a Structured Prompt**: Structure your prompt to explicitly ask the model to choose from the provided options. You can phrase it like this: - Based on the following context, please choose the best option: [Context]. Options: A) [Option 1], B) [Option 2], C) [Option 3], D) [Option 4]. 4. **Encourage Elaboration**: If you want the model to provide reasoning or elaboration on the chosen option, you can add a follow-up request. For example: - Please choose the best option and explain why you chose it. 5. **Iterate if Necessary**: If the initial response doesn’t meet your expectations, you can refine your options or context and try again. This iterative process can help you hone in on the desired output. ### Example Here’s a practical example of how to use the Multiple Choice prompt technique: **Prompt**: Based on the following context, please choose the best option: 'What is the most effective way to improve customer satisfaction in a retail store?' Options: A) Implementing a loyalty program, B) Reducing prices, C) Enhancing staff training, D) Increasing store hours.### Expected Output The model might respond with something like: I choose option C) Enhancing staff training because well-trained staff can provide better service, address customer concerns more effectively, and create a positive shopping experience, which ultimately leads to higher customer satisfaction.By using this technique, you can effectively limit the text generation options and guide the model towards producing focused and relevant responses.\",\n",
        "    \"Combining seed-word prompting with other techniques in ChatGPT text generation can enhance the quality, relevance, and creativity of the generated content. Here are several reasons why this combination is beneficial: 1. **Enhanced Contextualization**: Seed-word prompting provides a specific starting point, while other techniques (like multiple-choice prompts or structured queries) can further refine the context. This leads to more coherent and contextually appropriate responses. 2. **Increased Relevance**: By using seed words alongside techniques like specifying the desired format or style, users can guide the model to produce outputs that are more aligned with their needs. This reduces the likelihood of irrelevant or off-topic content. 3. **Improved Creativity**: Combining seed words with brainstorming techniques or open-ended prompts can stimulate more creative responses. The seed words can serve as inspiration, while the other techniques encourage the model to explore various angles or ideas. 4. **Focused Output**: Techniques such as multiple-choice prompts can help narrow down the options for the model, while seed words set the thematic direction. This combination allows users to obtain focused outputs without overwhelming the model with too many possibilities. 5. **Structured Responses**: Using seed words in conjunction with structured prompts (like lists or outlines) can help organize the generated content. This is particularly useful for tasks that require clarity and structure, such as reports or summaries. 6. **Iterative Refinement**: Combining techniques allows for iterative refinement of the output. For example, a user can start with seed words, generate a response, and then use follow-up prompts to clarify or expand on specific points, leading to a more polished final product. 7. **Diverse Perspectives**: By integrating seed-word prompting with techniques that encourage exploration of different viewpoints (like asking for pros and cons), users can obtain a more comprehensive understanding of a topic. 8. **User Engagement**: Combining techniques can make the interaction more engaging for users. It allows for a more dynamic conversation where users can guide the model in real-time, leading to a more satisfying experience. In summary, combining seed-word prompting with other techniques in ChatGPT text generation creates a more powerful and flexible approach, enabling users to harness the model's capabilities more effectively and achieve their desired outcomes.\",\n",
        "    \"Role prompting is a technique where you assign a specific role or persona to ChatGPT to guide its output in a desired direction. When combined with other prompt engineering techniques, role prompting can enhance the quality and relevance of the generated text. Here’s how to effectively use role prompting alongside other techniques: ### Steps to Use Role Prompting with Other Techniques 1. **Define the Role**: Clearly specify the role you want ChatGPT to assume. This could be a professional (e.g., a doctor, teacher, or consultant), a character (e.g., a historical figure or fictional character), or a specific perspective (e.g., a skeptic or an enthusiast). 2. **Combine with Seed Words**: Use seed words to provide context for the role. For example: - As a financial advisor, please explain the benefits of investing in stocks. Seed words: 'diversification', 'long-term growth', 'risk management'. 3. **Incorporate Multiple-Choice Prompts**: After establishing the role, you can present multiple-choice options to guide the response further. For example: - As a travel expert, choose the best destination for a family vacation from the following options: A) Disneyland, B) National Park, C) Beach Resort. Explain your choice. 4. **Use Structured Prompts**: Ask the model to respond in a specific format that aligns with the role. For instance: - As a nutritionist, provide a meal plan for a week. Format: Day 1: Breakfast, Lunch, Dinner. 5. **Encourage Elaboration**: After the initial response, prompt the model to elaborate on its answer. For example: - As a historian, summarize the causes of World War I and then discuss the long-term impacts. 6. **Iterative Refinement**: Use follow-up questions to refine the output. For example: - As a marketing strategist, what are three key strategies for social media marketing? Can you elaborate on the first one? 7. **Set Constraints**: Specify any constraints or limitations to guide the output more effectively. For example: - As a budget travel expert, suggest three affordable travel destinations for under $500. ### Example of Role Prompting Combined with Other Techniques **Prompt**: As a career coach, please provide advice for someone looking to transition into a tech career. Seed words: 'skills', 'networking', 'resume'. Additionally, list three key steps to take in this transition. ### Expected Output The model might respond with: As a career coach, transitioning into a tech career involves several important steps. Here are three key steps to consider: 1. **Identify Transferable Skills**: Assess your current skills and see how they can apply to tech roles. Skills like problem-solving, communication, and project management are valuable in tech. 2. **Build a Network**: Connect with professionals in the tech industry through networking events, online forums, and social media platforms like LinkedIn. Networking can open doors to job opportunities and mentorship. 3. **Update Your Resume**: Tailor your resume to highlight relevant skills and experiences. Consider taking online courses or certifications to bolster your qualifications in specific tech areas.By using role prompting in conjunction with other prompt engineering techniques, you can effectively guide ChatGPT's output to be more relevant, structured, and aligned with your specific needs. This approach enhances the interaction and helps achieve more satisfactory results.\"\n",
        "]\n",
        "\n",
        "# 创建数据字典并转换为Dataset对象\n",
        "dataset = Dataset.from_dict({\n",
        "    \"question\": questions,\n",
        "    \"contexts\": contexts,\n",
        "    \"answer\": chatbot_answers,\n",
        "    \"ground_truth\": ground_truths\n",
        "})\n",
        "\n",
        "# 定义评估指标\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "]\n",
        "\n",
        "# 初始化评估用的LLM模型\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "\n",
        "try:\n",
        "    # 进行评估\n",
        "    result = evaluate(\n",
        "        metrics=metrics,\n",
        "        dataset=dataset,\n",
        "        llm=evaluator_llm,\n",
        "        embeddings=OpenAIEmbeddings(),\n",
        "    )\n",
        "\n",
        "    # 打印评估结果\n",
        "    print(result)\n",
        "\n",
        "    # 将结果转换为pandas DataFrame以进行更详细的分析\n",
        "    result_df = result.to_pandas()\n",
        "    print(result_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"评估过程中出现错误: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674,
          "referenced_widgets": [
            "d0a140df17bc4099afe22a26336ffe5b",
            "ed8264949e3942fbb6d8c6e746041665",
            "5e8fd3eab1854a569deecf6e641ba893",
            "1801bdb6590a4a2fb20c5ffa157c3c47",
            "35df4e69267c4f7faf866e88f2b8c114",
            "6a91b82443224dc9bb6b3f50a70e5dce",
            "c62f45c3ac6e40c4af89c778b4f99090",
            "da68a0f86d3243b4bb2a7f78c028685e",
            "681541b774b7416993755cf1cdbbbf33",
            "63cc8f922bbb4a21a54ab259b606a4c8",
            "409b6cc9828e4969b4afb75c27bb12af"
          ]
        },
        "id": "_fPdE9GX8Y43",
        "outputId": "dc5abf78-53f6-4003-a631-8f8fcbfe2a7d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0a140df17bc4099afe22a26336ffe5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'faithfulness': 0.1419, 'answer_relevancy': 0.9675, 'context_precision': 0.8000, 'context_recall': 0.9000}\n",
            "                                            question  \\\n",
            "0  How can customer reviews be grouped into clust...   \n",
            "1  What is the purpose of seed-word prompting in ...   \n",
            "2  How to use Multiple Choice prompt technique wi...   \n",
            "3  Why combine seed-word prompting with other tec...   \n",
            "4  How to use role prompting to guide ChatGPT's o...   \n",
            "\n",
            "                                            contexts  \\\n",
            "0  [This technique is useful for tasks such as da...   \n",
            "1  [ generally composed of 3 main elements:\\n\\nta...   \n",
            "2  [net.\\n\\nRole: Poet\\n\\nPrompt formula: \"Genera...   \n",
            "3  [ generally composed of 3 main elements:\\n\\nta...   \n",
            "4  [ generally composed of 3 main elements:\\n\\nta...   \n",
            "\n",
            "                                              answer  \\\n",
            "0  Customer reviews can be grouped into clusters ...   \n",
            "1  Seed-word prompting in generating text with Ch...   \n",
            "2  Using the Multiple Choice prompt technique wit...   \n",
            "3  Combining seed-word prompting with other techn...   \n",
            "4  Role prompting is a technique where you assign...   \n",
            "\n",
            "                                        ground_truth  faithfulness  \\\n",
            "0  The model should be provided with a set of cus...      0.137931   \n",
            "1  The purpose of seed-word prompting in generati...      0.000000   \n",
            "2  This technique presents a model with a questio...      0.125000   \n",
            "3  Seed-word prompting is combined with other tec...      0.181818   \n",
            "4  The role prompting technique is used to guide ...      0.264706   \n",
            "\n",
            "   answer_relevancy  context_precision  context_recall  \n",
            "0          1.000000                1.0             1.0  \n",
            "1          0.992385                0.0             0.5  \n",
            "2          0.974488                1.0             1.0  \n",
            "3          0.976731                1.0             1.0  \n",
            "4          0.893652                1.0             1.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "# 定义一个函数来截断长文本\n",
        "def truncate_text(text, max_length=100):\n",
        "    return text if len(text) <= max_length else text[:max_length] + \"...\"\n",
        "\n",
        "# 应用截断函数到特定列\n",
        "for col in ['question', 'contexts', 'answer', 'ground_truth']:\n",
        "    result_df[col] = result_df[col].apply(lambda x: truncate_text(str(x), max_length=200))\n",
        "\n",
        "# 使用styler来改善显示\n",
        "styler = result_df.style.set_properties(**{'text-align': 'left'})\n",
        "styler = styler.set_table_styles([dict(selector='th', props=[('text-align', 'left')])])\n",
        "\n",
        "print(\"\\nDetailed Results:\")\n",
        "display(HTML(styler.to_html()))\n",
        "\n",
        "# 显示每一行的详细信息\n",
        "for index, row in result_df.iterrows():\n",
        "    print(f\"\\nDetailed view of row {index + 1}:\")\n",
        "    for col in result_df.columns:\n",
        "        print(f\"{col}:\\n{row[col]}\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q3ugISTB-bT9",
        "outputId": "9c8eb8e3-e461-48cb-886d-25b40d6fcc3f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed Results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_d0237 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_d0237_row0_col0, #T_d0237_row0_col1, #T_d0237_row0_col2, #T_d0237_row0_col3, #T_d0237_row0_col4, #T_d0237_row0_col5, #T_d0237_row0_col6, #T_d0237_row0_col7, #T_d0237_row1_col0, #T_d0237_row1_col1, #T_d0237_row1_col2, #T_d0237_row1_col3, #T_d0237_row1_col4, #T_d0237_row1_col5, #T_d0237_row1_col6, #T_d0237_row1_col7, #T_d0237_row2_col0, #T_d0237_row2_col1, #T_d0237_row2_col2, #T_d0237_row2_col3, #T_d0237_row2_col4, #T_d0237_row2_col5, #T_d0237_row2_col6, #T_d0237_row2_col7, #T_d0237_row3_col0, #T_d0237_row3_col1, #T_d0237_row3_col2, #T_d0237_row3_col3, #T_d0237_row3_col4, #T_d0237_row3_col5, #T_d0237_row3_col6, #T_d0237_row3_col7, #T_d0237_row4_col0, #T_d0237_row4_col1, #T_d0237_row4_col2, #T_d0237_row4_col3, #T_d0237_row4_col4, #T_d0237_row4_col5, #T_d0237_row4_col6, #T_d0237_row4_col7 {\n",
              "  text-align: left;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_d0237\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_d0237_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
              "      <th id=\"T_d0237_level0_col1\" class=\"col_heading level0 col1\" >contexts</th>\n",
              "      <th id=\"T_d0237_level0_col2\" class=\"col_heading level0 col2\" >answer</th>\n",
              "      <th id=\"T_d0237_level0_col3\" class=\"col_heading level0 col3\" >ground_truth</th>\n",
              "      <th id=\"T_d0237_level0_col4\" class=\"col_heading level0 col4\" >faithfulness</th>\n",
              "      <th id=\"T_d0237_level0_col5\" class=\"col_heading level0 col5\" >answer_relevancy</th>\n",
              "      <th id=\"T_d0237_level0_col6\" class=\"col_heading level0 col6\" >context_precision</th>\n",
              "      <th id=\"T_d0237_level0_col7\" class=\"col_heading level0 col7\" >context_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_d0237_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_d0237_row0_col0\" class=\"data row0 col0\" >How can customer reviews be grouped into clusters based on sentiment?</td>\n",
              "      <td id=\"T_d0237_row0_col1\" class=\"data row0 col1\" >['This technique is useful for tasks such as data analysis, machine learning, and natural language processing.\\n\\n\\n\\n\\n\\nHow to use it with ChatGPT:\\n\\nThe model should be provided with a set of data...</td>\n",
              "      <td id=\"T_d0237_row0_col2\" class=\"data row0 col2\" >Customer reviews can be grouped into clusters based on sentiment using various techniques in natural language processing (NLP) and machine learning. Here’s a general approach to achieve this: 1. **Dat...</td>\n",
              "      <td id=\"T_d0237_row0_col3\" class=\"data row0 col3\" >The model should be provided with a set of customer reviews and asked to group them into clusters based on sentiment. The prompt should include the instruction to group the reviews based on sentiment.</td>\n",
              "      <td id=\"T_d0237_row0_col4\" class=\"data row0 col4\" >0.137931</td>\n",
              "      <td id=\"T_d0237_row0_col5\" class=\"data row0 col5\" >1.000000</td>\n",
              "      <td id=\"T_d0237_row0_col6\" class=\"data row0 col6\" >1.000000</td>\n",
              "      <td id=\"T_d0237_row0_col7\" class=\"data row0 col7\" >1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d0237_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_d0237_row1_col0\" class=\"data row1 col0\" >What is the purpose of seed-word prompting in generating text with ChatGPT?</td>\n",
              "      <td id=\"T_d0237_row1_col1\" class=\"data row1 col1\" >[' generally composed of 3 main elements:\\n\\ntask: a clear and concise statement of what the prompt is asking the model to generate.\\n\\ninstructions: the instructions that should be followed by the mo...</td>\n",
              "      <td id=\"T_d0237_row1_col2\" class=\"data row1 col2\" >Seed-word prompting in generating text with ChatGPT serves several important purposes: 1. **Guiding Context**: Seed words provide a starting point or context for the model, helping it understand the t...</td>\n",
              "      <td id=\"T_d0237_row1_col3\" class=\"data row1 col3\" >The purpose of seed-word prompting in generating text with ChatGPT is to ensure that the generated text focuses on specific keywords or concepts. By providing seed words, the model can be guided to ge...</td>\n",
              "      <td id=\"T_d0237_row1_col4\" class=\"data row1 col4\" >0.000000</td>\n",
              "      <td id=\"T_d0237_row1_col5\" class=\"data row1 col5\" >0.992385</td>\n",
              "      <td id=\"T_d0237_row1_col6\" class=\"data row1 col6\" >0.000000</td>\n",
              "      <td id=\"T_d0237_row1_col7\" class=\"data row1 col7\" >0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d0237_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_d0237_row2_col0\" class=\"data row2 col0\" >How to use Multiple Choice prompt technique with ChatGPT for limited text generation options?</td>\n",
              "      <td id=\"T_d0237_row2_col1\" class=\"data row2 col1\" >['net.\\n\\nRole: Poet\\n\\nPrompt formula: \"Generate a sonnet related to the seed word\\n\\n\\'love\\' as a poet\"\\n\\nExample 2: Text Completion\\n\\nTask: Complete a sentence\\n\\nInstructions: The completion sh...</td>\n",
              "      <td id=\"T_d0237_row2_col2\" class=\"data row2 col2\" >Using the Multiple Choice prompt technique with ChatGPT can help you generate limited text options effectively. Here’s how to implement this technique: 1. **Define the Context**: Start by clearly defi...</td>\n",
              "      <td id=\"T_d0237_row2_col3\" class=\"data row2 col3\" >This technique presents a model with a question or task and a set of predefined options as potential answers. It is useful for generating text that is limited to a specific set of options and can be u...</td>\n",
              "      <td id=\"T_d0237_row2_col4\" class=\"data row2 col4\" >0.125000</td>\n",
              "      <td id=\"T_d0237_row2_col5\" class=\"data row2 col5\" >0.974488</td>\n",
              "      <td id=\"T_d0237_row2_col6\" class=\"data row2 col6\" >1.000000</td>\n",
              "      <td id=\"T_d0237_row2_col7\" class=\"data row2 col7\" >1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d0237_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_d0237_row3_col0\" class=\"data row3 col0\" >Why combine seed-word prompting with other techniques in ChatGPT text generation?</td>\n",
              "      <td id=\"T_d0237_row3_col1\" class=\"data row3 col1\" >[' generally composed of 3 main elements:\\n\\ntask: a clear and concise statement of what the prompt is asking the model to generate.\\n\\ninstructions: the instructions that should be followed by the mo...</td>\n",
              "      <td id=\"T_d0237_row3_col2\" class=\"data row3 col2\" >Combining seed-word prompting with other techniques in ChatGPT text generation can enhance the quality, relevance, and creativity of the generated content. Here are several reasons why this combinatio...</td>\n",
              "      <td id=\"T_d0237_row3_col3\" class=\"data row3 col3\" >Seed-word prompting is combined with other techniques in ChatGPT text generation to ensure that the generated text focuses on specific aspects or features related to the seed word. By incorporating se...</td>\n",
              "      <td id=\"T_d0237_row3_col4\" class=\"data row3 col4\" >0.181818</td>\n",
              "      <td id=\"T_d0237_row3_col5\" class=\"data row3 col5\" >0.976731</td>\n",
              "      <td id=\"T_d0237_row3_col6\" class=\"data row3 col6\" >1.000000</td>\n",
              "      <td id=\"T_d0237_row3_col7\" class=\"data row3 col7\" >1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d0237_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_d0237_row4_col0\" class=\"data row4 col0\" >How to use role prompting to guide ChatGPT's output with other prompt engineering techniques?</td>\n",
              "      <td id=\"T_d0237_row4_col1\" class=\"data row4 col1\" >[' generally composed of 3 main elements:\\n\\ntask: a clear and concise statement of what the prompt is asking the model to generate.\\n\\ninstructions: the instructions that should be followed by the mo...</td>\n",
              "      <td id=\"T_d0237_row4_col2\" class=\"data row4 col2\" >Role prompting is a technique where you assign a specific role or persona to ChatGPT to guide its output in a desired direction. When combined with other prompt engineering techniques, role prompting ...</td>\n",
              "      <td id=\"T_d0237_row4_col3\" class=\"data row4 col3\" >The role prompting technique is used to guide the output of ChatGPT by providing a specific role for the model to take on. This technique is useful for generating text that is tailored to a specific c...</td>\n",
              "      <td id=\"T_d0237_row4_col4\" class=\"data row4 col4\" >0.264706</td>\n",
              "      <td id=\"T_d0237_row4_col5\" class=\"data row4 col5\" >0.893652</td>\n",
              "      <td id=\"T_d0237_row4_col6\" class=\"data row4 col6\" >1.000000</td>\n",
              "      <td id=\"T_d0237_row4_col7\" class=\"data row4 col7\" >1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Detailed view of row 1:\n",
            "question:\n",
            "How can customer reviews be grouped into clusters based on sentiment?\n",
            "\n",
            "contexts:\n",
            "['This technique is useful for tasks such as data analysis, machine learning, and natural language processing.\\n\\n\\n\\n\\n\\nHow to use it with ChatGPT:\\n\\nThe model should be provided with a set of data...\n",
            "\n",
            "answer:\n",
            "Customer reviews can be grouped into clusters based on sentiment using various techniques in natural language processing (NLP) and machine learning. Here’s a general approach to achieve this: 1. **Dat...\n",
            "\n",
            "ground_truth:\n",
            "The model should be provided with a set of customer reviews and asked to group them into clusters based on sentiment. The prompt should include the instruction to group the reviews based on sentiment.\n",
            "\n",
            "faithfulness:\n",
            "0.13793103448275862\n",
            "\n",
            "answer_relevancy:\n",
            "0.9999999999999997\n",
            "\n",
            "context_precision:\n",
            "0.9999999999\n",
            "\n",
            "context_recall:\n",
            "1.0\n",
            "\n",
            "\n",
            "Detailed view of row 2:\n",
            "question:\n",
            "What is the purpose of seed-word prompting in generating text with ChatGPT?\n",
            "\n",
            "contexts:\n",
            "[' generally composed of 3 main elements:\\n\\ntask: a clear and concise statement of what the prompt is asking the model to generate.\\n\\ninstructions: the instructions that should be followed by the mo...\n",
            "\n",
            "answer:\n",
            "Seed-word prompting in generating text with ChatGPT serves several important purposes: 1. **Guiding Context**: Seed words provide a starting point or context for the model, helping it understand the t...\n",
            "\n",
            "ground_truth:\n",
            "The purpose of seed-word prompting in generating text with ChatGPT is to ensure that the generated text focuses on specific keywords or concepts. By providing seed words, the model can be guided to ge...\n",
            "\n",
            "faithfulness:\n",
            "0.0\n",
            "\n",
            "answer_relevancy:\n",
            "0.992384748582258\n",
            "\n",
            "context_precision:\n",
            "0.0\n",
            "\n",
            "context_recall:\n",
            "0.5\n",
            "\n",
            "\n",
            "Detailed view of row 3:\n",
            "question:\n",
            "How to use Multiple Choice prompt technique with ChatGPT for limited text generation options?\n",
            "\n",
            "contexts:\n",
            "['net.\\n\\nRole: Poet\\n\\nPrompt formula: \"Generate a sonnet related to the seed word\\n\\n\\'love\\' as a poet\"\\n\\nExample 2: Text Completion\\n\\nTask: Complete a sentence\\n\\nInstructions: The completion sh...\n",
            "\n",
            "answer:\n",
            "Using the Multiple Choice prompt technique with ChatGPT can help you generate limited text options effectively. Here’s how to implement this technique: 1. **Define the Context**: Start by clearly defi...\n",
            "\n",
            "ground_truth:\n",
            "This technique presents a model with a question or task and a set of predefined options as potential answers. It is useful for generating text that is limited to a specific set of options and can be u...\n",
            "\n",
            "faithfulness:\n",
            "0.125\n",
            "\n",
            "answer_relevancy:\n",
            "0.9744884921744981\n",
            "\n",
            "context_precision:\n",
            "0.9999999999\n",
            "\n",
            "context_recall:\n",
            "1.0\n",
            "\n",
            "\n",
            "Detailed view of row 4:\n",
            "question:\n",
            "Why combine seed-word prompting with other techniques in ChatGPT text generation?\n",
            "\n",
            "contexts:\n",
            "[' generally composed of 3 main elements:\\n\\ntask: a clear and concise statement of what the prompt is asking the model to generate.\\n\\ninstructions: the instructions that should be followed by the mo...\n",
            "\n",
            "answer:\n",
            "Combining seed-word prompting with other techniques in ChatGPT text generation can enhance the quality, relevance, and creativity of the generated content. Here are several reasons why this combinatio...\n",
            "\n",
            "ground_truth:\n",
            "Seed-word prompting is combined with other techniques in ChatGPT text generation to ensure that the generated text focuses on specific aspects or features related to the seed word. By incorporating se...\n",
            "\n",
            "faithfulness:\n",
            "0.18181818181818182\n",
            "\n",
            "answer_relevancy:\n",
            "0.976731333992372\n",
            "\n",
            "context_precision:\n",
            "0.9999999999\n",
            "\n",
            "context_recall:\n",
            "1.0\n",
            "\n",
            "\n",
            "Detailed view of row 5:\n",
            "question:\n",
            "How to use role prompting to guide ChatGPT's output with other prompt engineering techniques?\n",
            "\n",
            "contexts:\n",
            "[' generally composed of 3 main elements:\\n\\ntask: a clear and concise statement of what the prompt is asking the model to generate.\\n\\ninstructions: the instructions that should be followed by the mo...\n",
            "\n",
            "answer:\n",
            "Role prompting is a technique where you assign a specific role or persona to ChatGPT to guide its output in a desired direction. When combined with other prompt engineering techniques, role prompting ...\n",
            "\n",
            "ground_truth:\n",
            "The role prompting technique is used to guide the output of ChatGPT by providing a specific role for the model to take on. This technique is useful for generating text that is tailored to a specific c...\n",
            "\n",
            "faithfulness:\n",
            "0.2647058823529412\n",
            "\n",
            "answer_relevancy:\n",
            "0.8936524548209999\n",
            "\n",
            "context_precision:\n",
            "0.9999999999\n",
            "\n",
            "context_recall:\n",
            "1.0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}